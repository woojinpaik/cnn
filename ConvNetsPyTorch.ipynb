{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional neural networks\n",
    "\n",
    "In this unit we will learn about **Convolutional Neural Networks (CNNs)**, which are specifically designed for computer vision.\n",
    "\n",
    "Computer vision is different from generic classification, because when we are trying to find a certain object in the picture, we are scanning the image looking for some specific **patterns** and their combinations. For example, when looking for a cat, we first may look for horizontal lines, which can form whiskers, and then certain combination of whiskers can tell us that it is actually a picture of a cat. Relative position and presence of certain patterns is important, and not their exact position on the image. \n",
    "\n",
    "To extract patterns, we will use the notion of **convolutional filters**. But first, let us load all dependencies and functions that we have defined in the previous units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-04-12 14:16:11--  https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/computer-vision-pytorch/pytorchcv.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 6540 (6.4K) [text/plain]\n",
      "Saving to: ‘pytorchcv.py.1’\n",
      "\n",
      "pytorchcv.py.1      100%[===================>]   6.39K  --.-KB/s    in 0.001s  \n",
      "\n",
      "2024-04-12 14:16:12 (9.22 MB/s) - ‘pytorchcv.py.1’ saved [6540/6540]\n",
      "\n",
      "Requirement already satisfied: torchvision in /usr/local/python/3.10.13/lib/python3.10/site-packages (0.17.2)\n",
      "Requirement already satisfied: numpy in /home/codespace/.local/lib/python3.10/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: torch==2.2.2 in /home/codespace/.local/lib/python3.10/site-packages (from torchvision) (2.2.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/codespace/.local/lib/python3.10/site-packages (from torchvision) (10.3.0)\n",
      "Requirement already satisfied: filelock in /home/codespace/.local/lib/python3.10/site-packages (from torch==2.2.2->torchvision) (3.13.3)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/codespace/.local/lib/python3.10/site-packages (from torch==2.2.2->torchvision) (4.10.0)\n",
      "Requirement already satisfied: sympy in /home/codespace/.local/lib/python3.10/site-packages (from torch==2.2.2->torchvision) (1.12)\n",
      "Requirement already satisfied: networkx in /home/codespace/.local/lib/python3.10/site-packages (from torch==2.2.2->torchvision) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/codespace/.local/lib/python3.10/site-packages (from torch==2.2.2->torchvision) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /home/codespace/.local/lib/python3.10/site-packages (from torch==2.2.2->torchvision) (2024.3.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/codespace/.local/lib/python3.10/site-packages (from torch==2.2.2->torchvision) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/codespace/.local/lib/python3.10/site-packages (from torch==2.2.2->torchvision) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/codespace/.local/lib/python3.10/site-packages (from torch==2.2.2->torchvision) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/codespace/.local/lib/python3.10/site-packages (from torch==2.2.2->torchvision) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/codespace/.local/lib/python3.10/site-packages (from torch==2.2.2->torchvision) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/codespace/.local/lib/python3.10/site-packages (from torch==2.2.2->torchvision) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/codespace/.local/lib/python3.10/site-packages (from torch==2.2.2->torchvision) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/codespace/.local/lib/python3.10/site-packages (from torch==2.2.2->torchvision) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/codespace/.local/lib/python3.10/site-packages (from torch==2.2.2->torchvision) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/codespace/.local/lib/python3.10/site-packages (from torch==2.2.2->torchvision) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/codespace/.local/lib/python3.10/site-packages (from torch==2.2.2->torchvision) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /home/codespace/.local/lib/python3.10/site-packages (from torch==2.2.2->torchvision) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/codespace/.local/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.2->torchvision) (12.4.99)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/codespace/.local/lib/python3.10/site-packages (from jinja2->torch==2.2.2->torchvision) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/codespace/.local/lib/python3.10/site-packages (from sympy->torch==2.2.2->torchvision) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: torchinfo in /usr/local/python/3.10.13/lib/python3.10/site-packages (1.8.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pytorchcv in /usr/local/python/3.10.13/lib/python3.10/site-packages (0.0.67)\n",
      "Requirement already satisfied: numpy in /home/codespace/.local/lib/python3.10/site-packages (from pytorchcv) (1.26.4)\n",
      "Requirement already satisfied: requests in /home/codespace/.local/lib/python3.10/site-packages (from pytorchcv) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.10/site-packages (from requests->pytorchcv) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.10/site-packages (from requests->pytorchcv) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from requests->pytorchcv) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.10/site-packages (from requests->pytorchcv) (2024.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/computer-vision-pytorch/pytorchcv.py\n",
    "%pip install torchvision\n",
    "%pip install torchinfo\n",
    "%pip install pytorchcv\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from torchinfo import summary\n",
    "import numpy as np\n",
    "import pytorchcv\n",
    "\n",
    "from pytorchcv import load_mnist, train, plot_results, plot_convolution, display_dataset\n",
    "load_mnist(batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional filters\n",
    "\n",
    "Convolutional filters are small windows that run over each pixel of the image and compute weighted average of the neighboring pixels.\n",
    "\n",
    "\n",
    "\n",
    "They are defined by matrices of weight coefficients. Let's see the examples of applying two different convolutional filters over our MNIST handwritten digits.\n",
    "\n",
    "The vertical edge filter emphasizes changes in intensity that occur vertically across the image, making it useful for detecting vertical lines and edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x300 with 12 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x300 with 12 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_convolution(torch.tensor([[-1.,0.,1.],[-1.,0.,1.],[-1.,0.,1.]]),'Vertical edge filter')\n",
    "plot_convolution(torch.tensor([[-1.,-1.,-1.],[0.,0.,0.],[1.,1.,1.]]),'Horizontal edge filter')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First filter is called a **vertical edge filter**, and it is defined by the following matrix:\n",
    "$$\n",
    "\\left(\n",
    "    \\begin{matrix}\n",
    "     -1 & 0 & 1 \\cr\n",
    "     -1 & 0 & 1 \\cr\n",
    "     -1 & 0 & 1 \\cr\n",
    "    \\end{matrix}\n",
    "\\right)\n",
    "$$\n",
    "When this filter goes over relatively uniform pixel field, all values add up to 0. However, when it encounters a vertical edge in the image, high spike value is generated. That's why in the images above you can see vertical edges represented by high and low values, while horizontal edges are averaged out.\n",
    "\n",
    "An opposite thing happens when we apply horizontal edge filter - horizontal lines are amplified, and vertical are averaged out.\n",
    "\n",
    "In classical computer vision, multiple filters were applied to the image to generate features, which then were used by machine learning algorithm to build a classifier. However, in deep learning we construct networks that **learn** best convolutional filters to solve classification problem.\n",
    "\n",
    "To do that, we introduce **convolutional layers**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Covolutional layers\n",
    "\n",
    "Convolutional layers are defined using `nn.Conv2d` construction. We need to specify the following:\n",
    "* `in_channels` - number of input channels. In our case we are dealing with a grayscale image, thus number of input channels is 1.\n",
    "* `out_channels` - number of filters to use. We will use 9 different filters, which will give the network plenty of opportunities to explore which filters work best for our scenario.\n",
    "* `kernel_size` is the size of the sliding window. Usually 3x3 or 5x5 filters are used.\n",
    "\n",
    "Simplest CNN will contain one convolutional layer. Given the input size 28x28, after applying nine 5x5 filters we will end up with a tensor of 9x24x24 (the spatial size is smaller, because there are only 24 positions where a sliding interval of length 5 can fit into 28 pixels).\n",
    "\n",
    "After convolution, we flatten 9x24x24 tensor into one vector of size 5184, and then add linear layer, to produce 10 classes. We also use `relu` activation function in between layers. \n",
    "\n",
    "The Rectified Linear Unit (ReLU) activation function is one of the most commonly used activation functions in neural networks, especially in deep learning models. The function is defined mathematically as:\n",
    "\n",
    "ReLU(x)=max(0,x)\n",
    "\n",
    "Here’s what this means:\n",
    "\n",
    "If x is greater than 0, the function returns x.\n",
    "If x is less than or equal to 0, the function returns 0.\n",
    "\n",
    "Properties of ReLU\n",
    "Non-linear: While it looks like a linear function, ReLU introduces a non-linearity (a simple threshold at 0), which allows models to learn more complex patterns.\n",
    "Computationally Efficient: It is very efficient to compute as it only requires checking if the input is positive or not.\n",
    "Sparse Activation: In practice, ReLU results in sparse activations; i.e., only a subset of neurons in a layer are active at a given time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchsummary in /usr/local/python/3.10.13/lib/python3.10/site-packages (1.5.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 9, 24, 24]             234\n",
      "           Flatten-2                 [-1, 5184]               0\n",
      "            Linear-3                   [-1, 10]          51,850\n",
      "================================================================\n",
      "Total params: 52,084\n",
      "Trainable params: 52,084\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.08\n",
      "Params size (MB): 0.20\n",
      "Estimated Total Size (MB): 0.28\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "%pip install torchsummary\n",
    "from torchsummary import summary\n",
    "\n",
    "class OneConv(nn.Module): # Defines a new class called OneConv that inherits from PyTorch's nn.Module. nn.Module is the base class for all neural network modules in PyTorch\n",
    "    def __init__(self): # This method initializes the OneConv class. The __init__ method is a special method in Python classes. It gets called when an object of the class is created\n",
    "        super(OneConv, self).__init__() # This line calls the constructor of the superclass (nn.Module). This is necessary to properly initialize the inherited class, setting up internal mechanisms that are crucial for the model's training and inference operations in PyTorch\n",
    "        self.conv = nn.Conv2d(in_channels=1,out_channels=9,kernel_size=(5,5)) # a 2D convolutional layer is defined and assigned to self.conv\n",
    "        self.flatten = nn.Flatten() # This creates an instance of the Flatten layer and assigns it to self.flatten. The Flatten layer converts a multi-dimensional input into a 1D array. This is typically used to transition from convolutional layers to fully connected layers\n",
    "        self.fc = nn.Linear(5184,10) # This line defines a fully connected (or linear) layer that is assigned to self.fc. The layer transforms an input of 5184 features to 10 features.\n",
    "\n",
    "    def forward(self, x): # The forward method defines the forward pass of the module. x is the input tensor that passes through the model\n",
    "        if x.dim() == 5 and x.size(2) == 1:  # Check for unexpected extra dimension\n",
    "            x = x.squeeze(2)\n",
    "        x = nn.functional.relu(self.conv(x)) # This line applies the defined convolutional layer self.conv to the input x, then applies the ReLU activation function to the output of the convolution\n",
    "        x = self.flatten(x) # This line applies the self.flatten layer to the output of the ReLU activation, converting all the feature maps into a single long vector, which can be fed into fully connected layers\n",
    "        x = nn.functional.log_softmax(self.fc(x),dim=1) # Applies the fully connected layer self.fc to the flattened vector x. The result is then passed through a log softmax function. log_softmax is a logarithmic version of the softmax function, which is used to compute probabilities for multi-class classification problems. The dim=1 argument specifies that the softmax should be applied to the second dimension, which corresponds to the class probabilities for each input in the batch\n",
    "\n",
    "        return  # The final processed tensor x, which contains the log probabilities of the classes, is returned from the forward method. This output can be used by a loss function during training to compute the error and update the model weights\n",
    "\n",
    "# Create an instance of the network\n",
    "net = OneConv()\n",
    "\n",
    "# Print the summary of the model\n",
    "summary(net,input_size=(1,1,28,28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that this network contains around 50k trainable parameters, compared to around 80k in fully-connected multi-layered networks. This allows us to achieve good results even on smaller datasets, because convolutional networks generalize much better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "nll_loss_nd(): argument 'input' (position 1) must be Tensor, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m hist \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m plot_results(hist)\n",
      "File \u001b[0;32m/workspaces/cnn/pytorchcv.py:61\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(net, train_loader, test_loader, optimizer, lr, epochs, loss_fn)\u001b[0m\n\u001b[1;32m     59\u001b[0m res \u001b[38;5;241m=\u001b[39m { \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m'\u001b[39m : [], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_acc\u001b[39m\u001b[38;5;124m'\u001b[39m: [], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m: [], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_acc\u001b[39m\u001b[38;5;124m'\u001b[39m: []}\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ep \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m---> 61\u001b[0m     tl,ta \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m     vl,va \u001b[38;5;241m=\u001b[39m validate(net,test_loader,loss_fn\u001b[38;5;241m=\u001b[39mloss_fn)\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mep\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m2\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Train acc=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mta\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Val acc=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mva\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Train loss=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtl\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Val loss=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvl\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/workspaces/cnn/pytorchcv.py:35\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(net, dataloader, lr, optimizer, loss_fn)\u001b[0m\n\u001b[1;32m     33\u001b[0m lbls \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(default_device)\n\u001b[1;32m     34\u001b[0m out \u001b[38;5;241m=\u001b[39m net(features\u001b[38;5;241m.\u001b[39mto(default_device))\n\u001b[0;32m---> 35\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlbls\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#cross_entropy(out,labels)\u001b[39;00m\n\u001b[1;32m     36\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     37\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/loss.py:216\u001b[0m, in \u001b[0;36mNLLLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnll_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/functional.py:2733\u001b[0m, in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2731\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2732\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 2733\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnll_loss_nd\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: nll_loss_nd(): argument 'input' (position 1) must be Tensor, not NoneType"
     ]
    }
   ],
   "source": [
    "hist = train(net,train_loader,test_loader,epochs=5)\n",
    "plot_results(hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we are able to achieve higher accuracy, and much faster, compared to the fully-connected networks from previous unit.\n",
    "\n",
    "We can also visualize the weights of our trained convolutional layers, to try and make some more sense of what is going on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,9)\n",
    "with torch.no_grad():\n",
    "    p = next(net.conv.parameters())\n",
    "    for i,x in enumerate(p):\n",
    "        ax[i].imshow(x.detach().cpu()[0,...])\n",
    "        ax[i].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that some of those filters look like they can recognize some oblique strokes, while others look pretty random. \n",
    "\n",
    "## Multi-layered CNNs and pooling layers\n",
    "\n",
    "First convolutional layers looks for primitive patterns, such as horizontal or vertical lines, but we can apply further convolutional layers on top of them to look for higher-level patterns, such as primitive shapes. Then more convolutional layers can combine those shapes into some parts of the picture, up to the final object that we are trying to classify. \n",
    "\n",
    "When doing so, we may also apply one trick: reducing the spatial size of the image. Once we have detected there is a horizontal stoke within sliding 3x3 window, it is not so important at which exact pixel it occurred. Thus we can \"scale down\" the size of the image, which is done using one of the **pooling layers**:\n",
    "\n",
    " * **Average Pooling** takes a sliding window (for example, 2x2 pixels) and computes an average of values within the window\n",
    " * **Max Pooling** replaces the window with the maximum value. The idea behind max pooling is to detect a presence of a certain pattern within the sliding window.\n",
    "\n",
    "Thus, in a typical CNN there would be several convolutional layers, with pooling layers in between them to decrease dimensions of the image. We would also increase the number of filters, because as patterns become more advanced - there are more possible interesting combinations that we need to be looking for.\n",
    "\n",
    "![An image showing several convolutional layers with pooling layers.](./images/cnn-pyramid.png)\n",
    "\n",
    "Because of decreasing spatial dimensions and increasing feature/filters dimensions, this architecture is also called **pyramid architecture**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLayerCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultiLayerCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(10, 20, 5)\n",
    "        self.fc = nn.Linear(320,10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(nn.functional.relu(self.conv1(x)))\n",
    "        x = self.pool(nn.functional.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 320)\n",
    "        x = nn.functional.log_softmax(self.fc(x),dim=1)\n",
    "        return x\n",
    "\n",
    "net = MultiLayerCNN()\n",
    "summary(net,input_size=(1,1,28,28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note a few things about this definition:\n",
    "* Instead of using `Flatten` layer, we are flattening the tensor inside `forward` function using `view` function. Since flattening layer does not have trainable weights, it is not essential that we create a separate layer instance within our class\n",
    "* We use just one instance of pooling layer in our model, also because it does not contain any trainable parameters, and this one instance can be effectively reused\n",
    "* The number of trainable parameters (~8.5K) is dramatically smaller than in previous cases. This happens because convolutional layers in general have few parameters, and dimensionality of the image before applying final dense layer is significantly reduced. Small number of parameters have positive impact on our models, because it helps to prevent overfitting even on smaller dataset sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = train(net,train_loader,test_loader,epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What you should probably observe is that we are able to achieve higher accuracy than with just one layer, and much faster - just with 1 or 2 epochs. It means that sophisticated network architecture needs much fewer data to figure out what is going on, and to extract generic patterns from our images.\n",
    "\n",
    "## Playing with real images from the CIFAR-10 dataset\n",
    "\n",
    "While our handwritten digit recognition problem may seem like a toy problem, we are now ready to do something more serious. Let's explore more advanced dataset of pictures of different objects, called [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html). It contains 60k 32x32 images, divided into 10 classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.Compose(\n",
    "    [torchvision.transforms.ToTensor(),\n",
    "     torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=14, shuffle=True)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=14, shuffle=False)\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_dataset(trainset,classes=classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A well-known architecture for CIFAR-10 is called [LeNet](https://en.wikipedia.org/wiki/LeNet), and has been proposed by *Yann LeCun*. It follows the same principles as we have outlined above, the main difference being 3 input color channels instead of 1. \n",
    "\n",
    "We also do one more simplification to this model - we do not use `log_softmax` as output activation function, and just return the output of last fully-connected layer. In this case we can just use `CrossEntropyLoss` loss function to optimize the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.conv3 = nn.Conv2d(16,120,5)\n",
    "        self.flat = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(120,64)\n",
    "        self.fc2 = nn.Linear(64,10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(nn.functional.relu(self.conv1(x)))\n",
    "        x = self.pool(nn.functional.relu(self.conv2(x)))\n",
    "        x = nn.functional.relu(self.conv3(x))\n",
    "        x = self.flat(x)\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "net = LeNet()\n",
    "\n",
    "summary(net,input_size=(1,3,32,32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training this network properly will take significant amount of time, and should preferably be done on GPU-enabled compute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.SGD(net.parameters(),lr=0.001,momentum=0.9)\n",
    "hist = train(net, trainloader, testloader, epochs=3, optimizer=opt, loss_fn=nn.CrossEntropyLoss())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy that we have been able to achieve with 3 epochs of training does not seem great. However, remember that blind guessing would only give us 10% accuracy, and that our problem is actually significantly more difficult than MNIST digit classification. Getting above 50% accuracy in such a short training time seems like a good accomplishment.\n",
    "\n",
    "## Takeaways\n",
    "\n",
    "In this unit, we have learned the main concept behind computer vision neural networks - convolutional networks. Real-life architectures that power image classification, object detection, and even image generation networks are all based on CNNs, just with more layers and some additional training tricks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
